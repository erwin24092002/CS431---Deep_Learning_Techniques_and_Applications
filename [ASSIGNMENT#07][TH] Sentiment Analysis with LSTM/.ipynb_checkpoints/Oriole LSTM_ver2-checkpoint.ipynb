{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân tích cảm xúc với LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong assignment này, chúng ta sẽ txem xét cách áp dụng các kỹ thuật deep learning vào việc phân tích cảm xúc. Phân tích cảm xúc có thể được xem như việc ta lấy một câu, đoạn văn, tài liệu, hoặc bất kỳ phần nào của ngôn ngữ tự nhiên, và xác định xem âm điệu của văn bản đó là tích cực, tiêu cực hay trung tính.\n",
    "\n",
    "Ghi chú này sẽ đề cập nhiều chủ đề như vectơ từ (word vector), recurrent neural networks và long short-term memory units (LSTMs). Sau khi hiểu rõ các thuật ngữ này, chúng ta sẽ xem qua các đoạn mã ví dụ cụ thể và kỹ thuật phân loại cảm xúc Tensorflow ở cuối phần ghi chú.\n",
    "\n",
    "Trước khi đi sâu vào các chi tiết cụ thể, chúng ta cùng thảo luận về lý do tại sao deep learning phù hợp với các bài toán xử lý ngôn ngữ tự nhiên (NLP).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning cho NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quá trình Xử lý ngôn ngữ tự nhiên gồm tất cả việc tạo ra các hệ thống xử lý hoặc \"hiểu\" ngôn ngữ để thực hiện các tác vụ nhất định. Các tác vụ này có thể bao gồm:\n",
    "\n",
    "* Trả lời câu hỏi - Công việc chính của các công nghệ như Siri, Alexa và Cortana\n",
    "* Phân tích cảm xúc - Xác định âm điệu cảm xúc đằng sau một đoạn văn bản\n",
    "* Ánh xạ từ hình ảnh sang văn bản - Tạo chú thích cho hình ảnh đầu vào\n",
    "* Dịch máy - Dịch một đoạn văn bản sang ngôn ngữ khác\n",
    "* Nhận dạng giọng nói - Có máy tính nhận dạng các từ được nói\n",
    "\n",
    "Trong thời kỳ tiền công nghệ deep learning, NLP là một lĩnh vực phát triển mạnh và có rất nhiều tiến bộ khác nhau. Tuy nhiên, trong tất cả những thành công trong các bài toán nói trên, NLP rất cần thiết để thiết kế các đặc tính kỹ thuật, do vậy chúng ta cần phải có kiến thức chuyên ngành về lĩnh vực ngôn ngữ học.\n",
    "\n",
    "Nghiên cứu lĩnh vực này trong toàn bộ 4 năm, các học viên cần phải thoải mái làm quen với các thuật ngữ như \"phonemes\" và \"morphemes\". Trong vài năm qua, deep learning đã có một sự tiến bộ đáng kinh ngạc và phần lớn loại bỏ được các yêu cầu ngặt về domain knowledege. Như một kết quả của việc giảm rào cản khi bắt đầu, các ứng dụng của các bài toán NLP là một trong những lĩnh vực lớn nhất trong việc nghiên cứu về deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để có thể hiểu được deep learning có thể ứng dụng thế nào, hãy suy nghĩ về các dạng khác nhau của data được sử dụng làm dữ liệu đầu vào cho các mô hình machine learning hoặc deep learning. Convolutional neural networks sử dụng các mảng với các giá trị pixels, sử dụng hồi quy logistic với các đặc trưng có thể định lượng được, và mô hình reinforcement learning với reward signals.\n",
    "Các đặc tính chung là dữ liệu đầu vào cần phải là dữ liệu vô hướng hoặc các ma trận với giá trị vô hướng. Tuy nhiên, đối với bài toán NLP, thì ta có thể nghĩ đến kiểu dữ liệu như thế này.\n",
    " \n",
    "![caption](Images/SentimentAnalysis.png)\n",
    "\n",
    "\n",
    "Loại kênh cung cấp thông tin này gặp nhiều vấn đề. Không có cách nào để chúng ta thực hiện các thao tác biến đổi như dot product hoặc backpropagation trên một chuỗi đơn. Thay vì dữ liệu đầu vào là một chuỗi, chúng ta cần chuyển đổi từng từ trong câu sang dạng vector.\n",
    "\n",
    "\n",
    "![caption](Images/SentimentAnalysis2.png)\n",
    "\n",
    "Các bạn có thể hình dung dữ liệu đầu vào của thuật toán phân tích cảm xúc có thể là một ma trận 16 x D chiều."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta muốn những vector này được tạo ra để chúng đại diện cho các từ trong các ngữ cảnh, ý nghĩa và ngữ nghĩa của nó. Ví dụ, chúng ta muốn vector của từ \"love\" và \"adore\" thể hiện trong cùng một lĩnh vực trong một không gian vector bởi vì chúng đều có một định nghĩa tương tự và đều sử dụng trong cùng một ngữ cảnh giống nhau. Biểu diễn vector của một từ còn được gọi là một word embedding.\n",
    "\n",
    "![caption](Images/SentimentAnalysis8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tạo ra các word embedding, chúng ta sử dụng mô hình khá phổ biến là \"Word2Vec\". Không đi quá sâu vào chi tiết, mô hình này tạo ra các word vector bằng việc xem xét ngữ cảnh mà từ đó xuất hiện trong các câu. Các từ trong cùng một ngữ cảnh giống nhau sẽ được đặt gần nhau trong một không gian vector. Trong ngôn ngữ tự nhiên, ngữ cảnh của các từ có thể rất quan trọng khi chúng ta cố gắng xác định nghĩa của các từ đó. Xem lại ví dụ trước về từ \"adore\" và \"love\", chúng ta cần xem xét loại câu mà chúng ta tìm thấy những từ này.\n",
    "\n",
    "![caption](Images/SentimentAnalysis9.png)\n",
    "\n",
    "Từ ngữ cảnh của câu, chúng ta có thể thấy cả 2 từ thường được dùng trong câu với ý nghĩa tích cực và thường có dạng từ hoặc cụm từ. Đây là dấu hiệu cho thấy cả 2 từ có điểm chung và có thể là từ đồng nghĩa. Ngữ cảnh cũng rất quan trọng khi ta xem xét cấu trúc ngữ pháp trong câu. Hầu hết các câu đều sẽ theo mô hình truyền thống là có động từ sau danh từ, tính từ trước danh từ, v.v Vì lý do này, mô hình có nhiều khả năng là vị trí của danh từ trong cùng một khu vực sẽ tương tự các danh từ khác. Mô hình lấy một tập dữ liệu lớn của các câu (ví dụ Wikipedia tiếng Anh) và xuất ra các vector cho mỗi từ duy nhất trong kho văn bản. Đầu ra của mô hình Word2Vec được gọi là embedding matrix.\n",
    "\n",
    "\n",
    "![caption](Images/SentimentAnalysis3.png)\n",
    "\n",
    "Embedding matrix này sẽ chứa các vector cho mỗi từ riêng biệt trong kho dữ liệu dùng để huấn luyện (training), các embedding matrices có thể chứa hơn 3 triệu vector từ.\n",
    "\n",
    "\n",
    "Mô hình Word2Vec được huấn luyện bằng việc lấy từng câu trong tập dữ liệu, phân một cửa sổ có kích thước cố định, và cố gắng dự đoán từ trung tâm của cửa sổ, được cho bởi các từ khác. Sử dụng Hàm tổn thất (Loss function) và quá trình tối ưu hóa, mô hình \n",
    "tạo ra các vector cho từng từ một. Các chi tiết cụ thể của quá trình huấn luyện này có thể phức tạp hơn một chút, vì vậy, bây giờ chúng tôi bỏ qua các chi tiết, nhưng điều quan trọng ở đây là đầu vào của bất kỳ phương pháp Deep Learning nào đối với bài toán NLP có thể là các vector từ.\n",
    "\n",
    "\n",
    "Để biết thêm thông tin về lý thuyết của phương pháp Word2Vec và cách nào để tạo ra các embedding của riêng mình, xem thêm Tensorflow's tại link sau:[tutorial](https://www.tensorflow.org/tutorials/word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chúng ta có các vector từ làm đầu vào. Hãy xem xét kiến trúc mạng thực tế mà chúng ta sẽ xây dựng. Khía cạnh duy nhất của dữ liệu NLP là có một khía cạnh thời gian. Mỗi từ trong câu phụ thuộc rất nhiều vào những gì đến trước và sau nó. Để giải thích sự phụ thuộc này, chúng tôi sử dụng RNN.\n",
    "\n",
    "Cấu trúc của RNN hơi khác so với cấu trúc mạng truyền thống Neural Network (NN) mà bạn có thể thấy. Mạng lan truyền thuận (feedforward network) bao gồm các nút đầu vào (input nodes), các đơn vị ẩn (hidden units) và các nút đầu ra (output nodes).\n",
    "\n",
    "\n",
    "![caption](Images/SentimentAnalysis17.png)\n",
    "\n",
    "\n",
    "Sự khác biệt chính yếu giữa các mạng feedforward và RNN là về mặt thời gian sau này. Trong RNN, mỗi từ trong chuỗi đầu vào sẽ được liên kết với một bước thời gian cụ thể. Trên thực tế, số bước thời gian sẽ bằng với độ dài tối đa của chuỗi.\n",
    "\n",
    "![caption](Images/SentimentAnalysis18.png)\n",
    "\n",
    "\n",
    "Liên kết với mỗi bước thời gian là một thành phần mới được gọi là một vector trạng thái ẩn h <sub> t </ sub>. Từ một mức độ cao, vectơ này tìm cách gói gọn và tóm tắt tất cả các thông tin đã được nhìn thấy trong các bước thời gian trước đó. Cũng giống như x <sub> t </ sub> là một vectơ gói gọn tất cả thông tin của một từ cụ thể, h <sub> t </ sub> là một vectơ tóm tắt thông tin từ các bước thời gian trước đó.\n",
    "\n",
    "Trạng thái ẩn là một hàm của cả vectơ từ hiện tại và vectơ trạng thái ẩn ở bước thời gian trước đó. Sigma chỉ ra rằng tổng của hai từ sẽ được đặt thông qua một hàm kích hoạt (activation function) (thường là một sigmoid hoặc tanh).\n",
    "\n",
    "\n",
    "![caption](Images/SentimentAnalysis15.png)\n",
    "\n",
    "Các thuật ngữ 2 W trong công thức trên đại diện cho ma trận trọng số (weight matrices). Nếu bạn nhìn kỹ vào các chữ viết trên, bạn sẽ thấy rằng có một ma trận trọng số W <sup> X </ sup> mà chúng ta sẽ dùng để nhân với input của chúng ta, và có một ma trận trọng số recurrent W <sup> H </ sup> được nhân với vector trạng thái ẩn ở bước thời gian trước đó. W <sup> H </ sup> là ma trận giữ nguyên trên tất cả các bước thời gian và ma trận trọng số W <sup> X </ sup>  khác nhau cho mỗi đầu vào.\n",
    "\n",
    "Độ lớn của các ma trận trọng số này ảnh hưởng đến số lượng vector trạng thái ẩn bị ảnh hưởng bởi vector hiện tại hoặc trạng thái ẩn trước đó. Như một bài tập, hãy xem xét công thức trên, và xem xét cách h <sub> t </ sub> sẽ thay đổi nếu W <sup> X </ sup> hoặc W <sup> H </ sup> có các giá trị lớn hoặc nhỏ.\n",
    "\n",
    "Hãy xem nhanh một ví dụ. Khi độ lớn của W <sup> H </ sup> lớn và độ lớn của W <sup> X </ sup>  nhỏ, chúng ta biết rằng h <sub> t </ sub> phần lớn bị ảnh hưởng bởi h <sub > t-1 </ sub> và không bị ảnh hưởng bởi x <sub> t </ sub>. Nói cách khác, vector trạng thái ẩn hiện tại cho thấy rằng từ hiện tại (current word) phần lớn không quan trọng đối với tóm tắt tổng thể của câu, và do đó nó sẽ có cùng giá trị với vectơ ở bước thời gian trước đó.\n",
    "\n",
    "Ma trận trọng số được cập nhật thông qua một quá trình tối ưu hoá được gọi là backpropagation theo thời gian.\n",
    "\n",
    "Vector trạng thái ẩn ở bước thời gian cuối cùng được đưa vào một phân lớp nhị phân softmax, nơi nó được nhân với một ma trận trọng số khác và được đặt thông qua hàm số softmax xuất ra các giá trị đầu ra là 0 và 1, cho chúng ta thấy xác xuất của cảm xúc tiêu cực và tích cực.\n",
    "![caption](Images/SentimentAnalysis16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory Units (LSTMs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Long Short Term Memory Units là các mô-đun mà bạn có thể đặt bên trong RNN. Ở mức độ cao, chúng đảm bảo rằng các vector trạng thái ẩn h có thể gói gọn thông tin về các phụ thuộc dài hạn trong văn bản. Như chúng ta thấy trong phần trước công thức cho h trong RNN truyền thống tương đối đơn giản. Phương pháp này không thể kết nối hiệu quả các thông tin được phân ra bởi nhiều hơn 1 vài bước thời gian lại với nhau. Chúng tôi có thể minh hoạ ý tưởng này bằng việc giải quyết các phụ thuộc dài hạn thông qua ví dụ trong lĩnh vực trả lời câu hỏi. Hàm của mô hình trả lời câu hỏi lấy một đoạn văn bản và trả lời câu hỏi đó với ngữ cảnh của nó. Hãy xem các ví dụ sau.\n",
    "\n",
    "![caption](Images/SentimentAnalysis4.png)\n",
    "\n",
    "\n",
    "Ở đây, chúng ta thấy rằng câu trung gian không ảnh hưởng đến câu hỏi được hỏi. Tuy nhiên, có một sự kết nối mạnh mẽ giữa các câu đầu tiên và thứ ba. Với RNN cổ điển, vector trạng thái ẩn ở cuối mạng có thể lưu trữ thêm thông tin về câu so với câu đầu tiên về số. Về cơ bản, việc thêm các đơn vị LSTM có thể xác định được thông tin chính xác và hữu ích cần được lưu trữ trong vector trạng thái ẩn.\n",
    "\n",
    "Xem xét đơn vị LSTM dưới góc nhìn kỹ thuật, các đơn vị được lấy từ vector  từ hiện tại x<sub>t</sub> và xuất ra các vector trạng thái ẩn h<sub>t</sub> . Trong những đơn vị này, công thức cho h<sub>t</sub> có một chút phức tạp hơn khi trong dạng typical RNN. Sự tính toán được chia thành 4 phần: cổng đầu vào (input gate), cổng quên (forget gate), cổng đầu ra (output gate) và vùng chứa bộ nhớ mới.\n",
    "\n",
    "\n",
    "![caption](Images/SentimentAnalysis10.png)\n",
    "\n",
    "\n",
    "Mỗi cổng sẽ lấy x <sub> t </ sub> và h <sub> t-1 </ sub> (không được hiển thị trong hình ảnh) làm đầu vào và sẽ thực hiện một số tính toán trên chúng để có được trạng thái trung gian. Mỗi trạng thái trung gian được nạp vào các pipeline khác nhau và cuối cùng thông tin được tổng hợp thành h <sub> t </ sub>. Để đơn giản, chúng ta sẽ không đi vào các công thức cụ thể cho mỗi cổng, nhưng đáng lưu ý rằng mỗi cổng này có thể được coi là các mô-đun khác nhau trong LSTM mà mỗi hàm có các chức năng khác nhau. Cổng đầu vào xác định mức độ nhấn mạnh vào mỗi đầu vào, cổng quên xác định thông tin mà chúng ta sẽ vứt bỏ và cổng đầu ra xác định h <sub> t </ sub> cuối cùng dựa trên các trạng thái trung gian. Để biết thêm thông tin về việc hiểu các chức năng của các cổng khác nhau và phương trình đầy đủ, hãy xem bài đăng blog [tuyệt vời] của Christopher Olah (http://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
    "\n",
    "Nhìn lại ví dụ đầu tiên với câu hỏi \"Tổng của hai con số là bao nhiêu?\", Mô hình sẽ phải được huấn luyện về các loại câu hỏi và câu trả lời tương tự. Các đơn vị LSTM sau đó sẽ có thể nhận ra rằng bất kỳ câu nào không có con số có thể sẽ không ảnh hưởng đến câu trả lời cho câu hỏi, và do đó, đơn vị sẽ có thể sử dụng cổng bị quên để loại bỏ các thông tin không cần thiết về con chó và giữ thông tin về các con số."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khung phân tích cảm xúc như là một bài toán deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như đã nhắc phần trước, bài toán phân tích cảm xúc bao gồm việc lấy một chuỗi từ làm đầu vào và quyết định xem cảm xúc trong đó là tích cực, tiêu cực hay trung tính. Chúng ta có thể phân bài toán cụ thể (và trong hầu hết các bài toán NLP khác) thành 5 thành phần:\n",
    "    1) Huấn luyện một mô hình phát sinh ra vector từ (như mô hình Word2Vec) hoặc tải lên các vector từ tiền huấn luyện.\n",
    "    2) Tạo một ma trận ID cho tập huấn luyện (chúng ta sẽ thảo luận sau) \n",
    "    3) Tạo ra đồ thị RNN (với đơn vị LSTM)\n",
    "    4) Huấn luyện \n",
    "    5) Kiểm định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, chúng ta muốn tạo ra vector từ. Một cách đơn giản, chúng ta sử dụng mô hình tiền huấn luyện (pretrained model)\n",
    "\n",
    "Như một trong những người chơi lớn trong lĩnh vực ML game, Google có thể huấn luyện một mô hình Word2Vec trên một bộ dữ liệu từ Google News có thể chứa tới hơn 100 tỷ các từ khác nhau. Từ mô hình đó, Google có thể tạo ra hơn 3 triệu vector từ, với mỗi từ có bậc 300. (https://code.google.com/archive/p/word2vec/#Pre-trained_word_and_phrase_vectors) \n",
    "\n",
    "Trong kịch bản lý tưởng, chúng tôi sử dụng các vector này, nhưng ma trận vector từ phải đủ lớn (3.6GB), chúng tôi sử dụng nhiều hơn một ma trận quản lý mà việc huấn luyện sử dụng [GloVe](http://nlp.stanford.edu/projects/glove/), một mô hình phát sinh các vector word tương tự nhau. Ma trận chức 400,000 vector từ, mỗi từ có số chiều là 50.\n",
    "\n",
    "Chúng ta sẽ imprt 2 cấu trúc dữ liệu khác nhau, một sử dụng danh sách Python với 400,000 từ, mà một gồm 400,000 x 50 chiều của ma trận embedding có thể chứa tất cả các giá trị của vector từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để chắc chắn mọi thứ được load lên một cách chính xác, chúng ta cần xem xét số chiều của danh sách từ vựng và ma trận embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "11083\n",
      "(400000, 50)\n",
      "0.4426276\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordsList.index('hi'))\n",
    "print(wordVectors.shape)\n",
    "\n",
    "word1 = 'baseball'\n",
    "vec1 = wordVectors[wordsList.index(word1)]/np.linalg.norm(wordVectors[wordsList.index(word1)])\n",
    "word2 = 'love'\n",
    "vec2 = wordVectors[wordsList.index(word2)]/np.linalg.norm(wordVectors[wordsList.index(word2)])\n",
    "\n",
    "\n",
    "#print(np.dot(, wordVectors[wordsList.index('adore')]))\n",
    "print(np.dot(vec1, vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể tìm kiếm trong danh sách từ một từ như \"baseball\", và tiếp cận vector của nó tương ứng thông qua ma trận embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
       "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
       "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
       "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
       "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
       "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
       "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
       "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
       "       -0.70315 ,  0.17157 ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "print (baseballIndex)\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta đã có các vector, bước đầu tiên là lấy câu đầu vào, sau đó xây dựng dạng biểu diễn vector của nó. Xem vét chúng ta có một câu đầu vào \"I thought the movie was incredible and inspiring\". Để lấy vector từ, chúng ta có thể sử dụng hàm tìm kiếm Tensorflow's embedding. Hàm này phân thành 2 phần, một cho embedding matrix ( ma trận wordVector trong trường hợp của chúg ta), và một cho ids của từng từ. Các ids vector có thể được coi là đại diện số nguyên của tập huấn luyện. Điều này về cơ bản chỉ là chỉ số hàng (row index) của mỗi từ. Hãy xem ví dụ để hiểu rõ hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "#firstSentence[8] and firstSentence[9] are going to be 0\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu pipeline có thể minh hoạ như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10x50 đầu ra có thể chứa 50 vector từ có chiều cho mỗi 10 từ trong câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9b8913c3c336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordVectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfirstSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước khi tạo ma trận id cho toàn bộ tập huấn luyện, trước tiên, hãy dành chút thời gian để trực quan hóa loại dữ liệu mà ta có. Điều này sẽ giúp ta xác định giá trị tốt nhất để thiết lập độ dài chuỗi tối đa của ta. Trong ví dụ trước, chúng tôi đã sử dụng độ dài tối đa là 10, nhưng giá trị này phần lớn phụ thuộc vào các yếu tố đầu vào mà bạn có."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set we're going to use is the Imdb movie review dataset. This set has 25,000 movie reviews, with 12,500 positive reviews and 12,500 negative reviews. Each of the reviews is stored in a txt file that we need to parse through. The positive reviews are stored in one directory and the negative reviews are stored in another. The following piece of code will determine total and average number of words in each review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 25000\n",
      "The total number of words in the files is 5844680\n",
      "The average number of words in the files is 233.7872\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
    "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Matplot library to visualize this data in a histogram format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram as well as the average number of words per file, we can safely say that most reviews will fall under 250 words, which is the max sequence length value we will set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can take a single file and transform it into our ids matrix. This is what one of the reviews looks like in text file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).\n"
     ]
    }
   ],
   "source": [
    "fname = positiveFiles[3] #Can use any valid index (not just 3)\n",
    "with open(fname) as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "        exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's convert to to an ids matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    37,     14,   2407, 201534,     96,  37314,    319,   7158,\n",
       "       201534,   6469,   8828,   1085,     47,   9703,     20,    260,\n",
       "           36,    455,      7,   7284,   1139,      3,  26494,   2633,\n",
       "          203,    197,   3941,  12739,    646,      7,   7284,   1139,\n",
       "            3,  11990,   7792,     46,  12608,    646,      7,   7284,\n",
       "         1139,      3,   8593,     81,  36381,    109,      3, 201534,\n",
       "         8735,    807,   2983,     34,    149,     37,    319,     14,\n",
       "          191,  31906,      6,      7,    179,    109,  15402,     32,\n",
       "           36,      5,      4,   2933,     12,    138,      6,      7,\n",
       "          523,     59,     77,      3, 201534,     96,   4246,  30006,\n",
       "          235,      3,    908,     14,   4702,   4571,     47,     36,\n",
       "       201534,   6429,    691,     34,     47,     36,  35404,    900,\n",
       "          192,     91,   4499,     14,     12,   6469,    189,     33,\n",
       "         1784,   1318,   1726,      6, 201534,    410,     41,    835,\n",
       "        10464,     19,      7,    369,      5,   1541,     36,    100,\n",
       "          181,     19,      7,    410,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    line=f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        if indexCounter < maxSeqLength:\n",
    "            try:\n",
    "                firstFile[indexCounter] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                firstFile[indexCounter] = 399999 #Vector for unknown words\n",
    "        indexCounter = indexCounter + 1\n",
    "firstFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same for each of our 25,000 reviews. We'll load in the movie training set and integerize it to get a 25000 x 250 matrix. This was a computationally expensive process, so instead of having you run the whole piece, we’re going to load in a pre-computed IDs matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "# fileCounter = 0\n",
    "# for pf in positiveFiles:\n",
    "#    with open(pf, \"r\") as f:\n",
    "#        indexCounter = 0\n",
    "#        line=f.readline()\n",
    "#        cleanedLine = cleanSentences(line)\n",
    "#        split = cleanedLine.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#            except ValueError:\n",
    "#                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#            indexCounter = indexCounter + 1\n",
    "#            if indexCounter >= maxSeqLength:\n",
    "#                break\n",
    "#        fileCounter = fileCounter + 1 \n",
    "\n",
    "# for nf in negativeFiles:\n",
    "#    with open(nf, \"r\") as f:\n",
    "#        indexCounter = 0\n",
    "#        line=f.readline()\n",
    "#        cleanedLine = cleanSentences(line)\n",
    "#        split = cleanedLine.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#            except ValueError:\n",
    "#                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#            indexCounter = indexCounter + 1\n",
    "#            if indexCounter >= maxSeqLength:\n",
    "#                break\n",
    "#        fileCounter = fileCounter + 1 \n",
    "# #Pass into embedding function and see if it evaluates. \n",
    "\n",
    "# np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.load('idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dat, lab = getTrainBatch()\n",
    "#for wid in dat[23]:\n",
    "#    print(wordsList[int(wid)])\n",
    "print(wordsList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can find a couple of helper functions that will be useful when training the network in a later step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,11499)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(13499,24999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499,13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we’re ready to start creating our Tensorflow graph. We’ll first need to define some hyperparameters, such as batch size, number of LSTM units, number of output classes, and number of training iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000\n",
    "numDimensions = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with most Tensorflow graphs, we’ll now need to specify two placeholders, one for the inputs into the network, and one for the labels. The most important part about defining these placeholders is understanding each of their dimensionalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels placeholder represents a set of values, each either [1, 0] or [0, 1], depending on whether each training example is positive or negative. Each row in the integerized input placeholder represents the integerized representation of each training example that we include in our batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our input data placeholder, we’re going to call the tf.nn.lookup() function in order to get our word vectors. The call to that function will return a 3-D Tensor of dimensionality batch size by max sequence length by word vector dimensions. In order to visualize this 3-D tensor, you can simply think of each data point in the integerized input tensor as the corresponding D dimensional vector that it refers to. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data in the format that we want, let’s look at how we can feed this input into an LSTM network. We’re going to call the tf.nn.rnn_cell.BasicLSTMCell function. This function takes in an integer for the number of LSTM units that we want. This is one of the hyperparameters that will take some tuning to figure out the optimal value. We’ll then wrap that LSTM cell in a dropout layer to help prevent the network from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we’ll feed both the LSTM cell and the 3-D tensor full of input data into a function called tf.nn.dynamic_rnn. This function is in charge of unrolling the whole network and creating a pathway for the data to flow through the RNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "lstmCell = tf.nn.rnn_cell.MultiRNNCell([lstmCell] * 1, state_is_tuple=True)\n",
    "init_state = lstmCell.zero_state(batchSize, tf.float32)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32, initial_state=init_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, another more advanced network architecture choice is to stack multiple LSTM cells on top of each other. This is where the final hidden state vector of the first LSTM feeds into the second. Stacking these cells is a great way to help the model retain more long term dependence information, but also introduces more parameters into the model, thus possibly increasing the training time, the need for additional training examples, and the chance of overfitting. For more information on how you can add stacked LSTMs to your model, check out Tensorflow's excellent [documentation](https://www.tensorflow.org/tutorials/recurrent#stacking_multiple_lstms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first output of the dynamic RNN function can be thought of as the last hidden state vector. This vector will be reshaped and then multiplied by a final weight matrix and a bias term to obtain the final output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll define correct prediction and accuracy metrics to track how the network is doing. The correct prediction formulation works by looking at the index of the maximum value of the 2 output values, and then seeing whether it matches with the training labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define a standard cross entropy loss with a softmax layer put on top of the final prediction values. For the optimizer, we’ll use Adam and the default learning rate of .001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-773132a4e1b5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’d like to use Tensorboard to visualize the loss and accuracy values, you can also run and the modify the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right values for your hyperparameters is a crucial part of training deep neural networks effectively. You'll find that your training loss curves can vary with your choice of optimizer (Adam, Adadelta, SGD, etc), learning rate, and network architecture. With RNNs and LSTMs in particular, some other important factors include the number of LSTM units and the size of the word vectors.\n",
    "\n",
    "* Learning Rate: RNNs are infamous for being diffult to train because of the large number of time steps they have. Learning rate becomes extremely important since we don't want our weight values to fluctuate wildly as a result of a large learning rate, nor do we want a slow training process due to a low learning rate. The default value of 0.001 is a good place to start. You should increase this value if the training loss is changing very slowly, and decrease if the loss is unstable.  \n",
    "* Optimizer: There isn't a consensus choice among researchers, but Adam has been widely popular due to having the adaptive learning rate property (Keep in mind that optimal learning rates can differ with the choice of optimizer).\n",
    "* Number of LSTM units: This value is largely dependent on the average length of your input texts. While a greater number of units provides more expressibility for the model and allows the model to store more information for longer texts, the network will take longer to train and will be computationally expensive. \n",
    "* Word Vector Size: Dimensions for word vectors generally range from 50 to 300. A larger size means that the vector is able to encapsulate more information about the word, but you should also expect a more computationally expensive model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of the training loop is that we first define a Tensorflow session. Then, we load in a batch of reviews and their associated labels. Next, we call the session’s `run` function. This function has two arguments. The first is called the \"fetches\" argument. It defines the value we’re interested in computing. We want our optimizer to be computed since that is the component that minimizes our loss function. The second argument is where we input our `feed_dict`. This data structure is where we provide inputs to all of our placeholders. We need to feed our batch of reviews and our batch of labels. This loop is then repeated for a set number of training iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training the network in this notebook (which will take at least a couple of hours), we’ll load in a pretrained model.\n",
    "\n",
    "If you decide to train this notebook on your own machine, note that you can track its progress using [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard). While the following cell is running, use your terminal to enter the directory that contains this notebook, enter `tensorboard --logdir=tensorboard`, and visit http://localhost:6006/ with a browser to keep an eye on your training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-656090d3b34f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0;31m#Next Batch of reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextBatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m    \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[0;31m#Write summary to Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "   #Next Batch of reviews\n",
    "   nextBatch, nextBatchLabels = getTrainBatch();\n",
    "   sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "   #Write summary to Tensorboard\n",
    "   if (i % 50 == 0):\n",
    "       summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "       writer.add_summary(summary, i)\n",
    "\n",
    "   #Save the network every 10,000 training iterations\n",
    "   if (i % 10000 == 0 and i != 0):\n",
    "       save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "       print(\"saved to %s\" % save_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pretrained model’s accuracy and loss curves during training can be found below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis6.png)\n",
    "![caption](Images/SentimentAnalysis7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the training curves above, it seems that the model's training is going well. The loss is decreasing steadily, and the accuracy is approaching 100 percent. However, when analyzing training curves, we should also pay special attention to the possibility of our model overfitting the training dataset. Overfitting is a common phenomenon in machine learning where a model becomes so fit to the training data that it loses the ability to generalize to the test set. This means that training a network until you achieve 0 training loss might not be the best way to get an accurate model that performs well on data it has never seen before. Early stopping is an intuitive technique commonly used with LSTM networks to combat this issue. The basic idea is that we train the model on our training set, while also measuring its performance on the test set every now and again. Once the test error stops its steady decrease and begins to increase instead, you'll know to stop training, since this is a sign that the network has begun to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a pretrained model involves defining another Tensorflow session, creating a Saver object, and then using that object to call the restore function. This function takes into 2 arguments, one for the current session, and one for the name of the saved model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we’ll load some movie reviews from our test set. Remember, these are reviews that the model has not been trained on and has never seen before. The accuracy for each test batch can be seen when you run the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getTestBatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c11bf9708fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextBatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTestBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for this batch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getTestBatch' is not defined"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we went over a deep learning approach to sentiment analysis. We looked at the different components involved in the whole pipeline and then looked at the process of writing Tensorflow code to implement the model in practice. Finally, we trained and tested the model so that it is able to classify movie reviews.\n",
    "\n",
    "With the help of Tensorflow, you can create your own sentiment classifiers to understand the large amounts of natural language in the world, and use the results to form actionable insights. Thanks for reading and following along!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
